# Facial Emotion Recognition - Web Application

A machine learning-based web application that detects emotions from facial images and saves user submissions to a database.

## ğŸ“‹ Project Structure

```
FACE_DETECTION/
â”œâ”€â”€ app.py                    # Flask web application
â”œâ”€â”€ model_training.py         # CNN model training script
â”œâ”€â”€ database.py               # Database initialization
â”œâ”€â”€ requirements.txt          # Python dependencies
â”œâ”€â”€ face_emotionModel.h5      # Trained emotion detection model
â”œâ”€â”€ database.db               # SQLite database (auto-created)
â”œâ”€â”€ link_web_app.txt          # Render deployment link
â”œâ”€â”€ .gitignore                # Git ignore rules
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html            # Web interface
â””â”€â”€ uploads/                  # Temporary image uploads (auto-created)
```

## ğŸ¯ Features

- **Facial Emotion Detection**: Recognizes 7 emotions (angry, disgust, fear, happy, neutral, sad, surprise)
- **Simple Web Interface**: HTML form with name input and image upload
- **Real-time Feedback**: Personalized messages based on detected emotion
- **Database Storage**: Saves submissions with name, emotion, confidence, and image
- **Submissions History**: View all submitted entries with timestamps
- **Mobile Responsive**: Works on desktop, tablet, and mobile devices

## ğŸš€ Quick Start

### 1. Install Dependencies
```bash
pip install -r requirements.txt
```

### 2. Train the Model (One-time setup)
```bash
python model_training.py
```
**Note**: This requires training data in `../train/` folder with emotion subfolders.
Training takes 5-10 minutes depending on your hardware.

### 3. Run the Flask App
```bash
python app.py
```
The app will start at `http://localhost:5000`

## ğŸ“– Usage

1. Open the web application
2. Enter your name
3. Upload a clear photo of your face
4. Click "Detect Emotion"
5. View your emotion prediction and feedback message
6. See all submissions in the "Recent Submissions" section

## ğŸ§  How It Works

1. **Image Upload**: User uploads an image via the web form
2. **Face Detection**: OpenCV detects face(s) in the image
3. **Preprocessing**: Face is cropped, resized to 48x48, and normalized
4. **Emotion Prediction**: CNN model predicts emotion (0-1 confidence for each class)
5. **Database Storage**: Result and image stored in SQLite database
6. **Feedback**: User receives personalized message based on emotion

## ğŸ”§ Model Architecture

```
Input (48x48x1 grayscale image)
    â†“
Conv2D(32) â†’ BatchNorm â†’ ReLU â†’ Conv2D(32) â†’ BatchNorm â†’ MaxPool â†’ Dropout
    â†“
Conv2D(64) â†’ BatchNorm â†’ ReLU â†’ Conv2D(64) â†’ BatchNorm â†’ MaxPool â†’ Dropout
    â†“
Conv2D(128) â†’ BatchNorm â†’ ReLU â†’ Conv2D(128) â†’ BatchNorm â†’ MaxPool â†’ Dropout
    â†“
Flatten
    â†“
Dense(256) â†’ BatchNorm â†’ ReLU â†’ Dropout
    â†“
Dense(128) â†’ BatchNorm â†’ ReLU â†’ Dropout
    â†“
Dense(7) â†’ Softmax (Output: emotion probabilities)
```

## ğŸ“Š Supported Emotions

1. **Angry** - Detected from furrowed brows, tight lips
2. **Disgust** - Detected from wrinkled nose, raised upper lip
3. **Fear** - Detected from wide eyes, raised eyebrows
4. **Happy** - Detected from raised cheeks, smile
5. **Neutral** - Detected from relaxed facial features
6. **Sad** - Detected from lowered eyebrows, downturned mouth
7. **Surprise** - Detected from raised eyebrows, open mouth

## ğŸ—„ï¸ Database Schema

**users_submissions table:**
- `id`: INTEGER PRIMARY KEY (auto-increment)
- `name`: TEXT (student name)
- `detected_emotion`: TEXT (emotion category)
- `emotion_confidence`: REAL (0-1 confidence score)
- `image_data`: BLOB (stored image file)
- `submission_timestamp`: DATETIME (submission time)
- `feedback_message`: TEXT (personalized response)

## ğŸ› Troubleshooting

### Model not found error
**Solution**: Run `python model_training.py` first to train the model

### No face detected error
**Solution**: Ensure the image shows a clear, frontal face

### Port already in use
**Solution**: Run on a different port:
```bash
python -c "from app import app; app.run(host='0.0.0.0', port=5001)"
```

### Database locked error
**Solution**: Close any existing Flask instances and try again

## ğŸ“ API Endpoints

- `GET /` - Serves the main web interface
- `POST /predict` - Process image and predict emotion
  - **Input**: Form data with `name` and `image` file
  - **Output**: JSON with emotion, confidence, and message
- `GET /submissions` - Retrieve all submissions
  - **Output**: JSON array of all submissions
- `GET /health` - Health check endpoint
  - **Output**: JSON with status and timestamp

## ğŸŒ Deployment (Render)

1. Push code to GitHub repository
2. Connect Render to GitHub
3. Create new Web Service on Render
4. Set build command: `pip install -r requirements.txt`
5. Set start command: `python app.py`
6. Add environment variable: `PORT=10000`
7. Deploy and copy the deployment link to `link_web_app.txt`

## âš ï¸ Important Notes

- **Training Data**: Ensure `../train/` and `../test/` folders exist with emotion subfolders
- **Face Detection**: Works best with clear, frontal face images
- **Image Size Limit**: Maximum 5MB per image
- **Supported Formats**: JPG, PNG, GIF, BMP
- **Database**: Created automatically on first run as `database.db`

## ğŸ”’ Security Features

- File type validation (only image formats allowed)
- File size limit enforcement (5MB max)
- HTML escaping for XSS prevention
- CSRF protection ready (add if needed)
- Secure model loading
- Safe database operations with parameterized queries

## ğŸ“ˆ Future Improvements

- Model accuracy optimization
- Real-time video stream support
- Multiple face detection and analysis
- Emotion statistics and trends
- User authentication and profiles
- Model confidence threshold tuning
- Batch image upload
- Export results as CSV/PDF

## ğŸ“„ License

This project is for educational purposes.

## ğŸ‘¨â€ğŸ’» Author

Created as an AI assignment for CSC 415.

## ğŸ“ Support

For issues or questions, refer to the code comments and error messages provided by the application.
